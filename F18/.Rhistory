plotLines(newY[newY$language=="Clojure",], col="blue")
# Log scale: prediction intervals for the top and bottom curves
# Empty plot
plot(log(pr_mean)~lcommits, main="log-Prediction interval\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlab="log(commits)", ylab="log(bugged commits)")
plotLines <- function(Ysub, col="black") {
lines(Ysub$lcommits, log(Ysub$pr_mean), lty=1, col=col)
lines(Ysub$lcommits, log(qnbinom(1-0.01/16, mu=Ysub$pr_mean, size=nbfit$theta)),
lty=2, col=col)
lines(Ysub$lcommits, log(qnbinom(0.01/16, mu=Ysub$pr_mean, size=nbfit$theta)),
lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
par(mfrow=c(1,2))
# Original scale: confidence intervals for the top and bottom curves
# Empty plot
plot(pr_mean~commits, main="CI for the mean,\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlim=c(0, 800), ylim=c(0,400), xlab="commits", ylab="bugged commits")
plotLines <- function(Ysub, col="black") {
lines(Ysub$commits, Ysub$pr_mean, lty=1, col=col)
lines(Ysub$commits, Ysub$pr_mean+qnorm(1-0.01/16)*Ysub$pr_se, lty=2, col=col)
lines(Ysub$commits, Ysub$pr_mean-qnorm(1-0.01/16)*Ysub$pr_se, lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
# Original scale: prediction intervals for the top and bottom curves
# Empty plot
plot(pr_mean~commits, main="Prediction interval\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlim=c(0, 800), ylim=c(0,400), xlab="commits", ylab="bugged commits")
plotLines <- function(Ysub, col="black") {
lines(Ysub$commits, Ysub$pr_mean, lty=1, col=col)
lines(Ysub$commits, qnbinom(1-0.01/16, mu=Ysub$pr_mean, size=nbfit$theta),
lty=2, col=col)
lines(Ysub$commits, qnbinom(0.01/16, mu=Ysub$pr_mean, size=nbfit$theta),
lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
# Plot predicted means for all the languages
par(mfrow=c(1,2))
# Log scale
plot(log(pr_mean)~lcommits, main="log(Exp. values), all languages",
data=newY[newY$language==levels(Y$language)[1],], type="l",
ylab="log(bugged commits)")
for (i in 2:16) {
lines(log(pr_mean)~lcommits,
data=newY[newY$language==levels(Y$language)[i],])
}
# Original scale
plot(pr_mean~commits, main="Exp. values, all languages",
data=newY[newY$language==levels(Y$language)[1],], type="l",
xlim=c(0, 800), ylim=c(0,400), ylab="bugged commits")
for (i in 2:16) {
lines(pr_mean~commits,
data=newY[newY$language==levels(Y$language)[i],])
}
# Set up probability of FP and FN
fp <- 0.3
fn <- 0.3
# Function to get parameter values
getParams <- function(Ystar) {
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Ystar)
s <- summary(nbfit)$coefficients
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Ystar)
s_r <- summary(nbfit_r)$coefficients
# Return params, incluing Scala
out <- c(s[,1], s_r[6, 1])
names(out) <- c(dimnames(s)[[1]][1:5], levels(Y$language))
out
}
# Perform sampling
set.seed(1)
params <- matrix(rep(NA,21*100), nrow=21)
for (i in 1:100) {
# Sample rows
Ystar <- Y[sample(1:nrow(Y), replace = T),]
# Adjust for tp and fp
Ystar$bcommits <- rbinom(n=nrow(Ystar), size=Ystar$bcommits, prob=1-fp) +
rbinom(n=nrow(Ystar), size=Ystar$commits, prob=fn)
# Get parameters
params[i,] <- getParams(Ystar)
}
getParams(Ystar)
dim(getParams(Ystar))
length(getParams(Ystar))
# Set up probability of FP and FN
fp <- 0.3
fn <- 0.3
# Function to get parameter values
getParams <- function(Ystar) {
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Ystar)
s <- summary(nbfit)$coefficients
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Ystar)
s_r <- summary(nbfit_r)$coefficients
# Return params, incluing Scala
out <- c(s[,1], s_r[6, 1])
names(out) <- c(dimnames(s)[[1]][1:5], levels(Y$language))
out
}
# Perform sampling
set.seed(1)
params <- matrix(rep(NA,21*100), nrow=21)
for (i in 1:100) {
# Sample rows
Ystar <- Y[sample(1:nrow(Y), replace = T),]
# Adjust for tp and fp
Ystar$bcommits <- rbinom(n=nrow(Ystar), size=Ystar$bcommits, prob=1-fp) +
rbinom(n=nrow(Ystar), size=Ystar$commits, prob=fn)
# Get parameters
params[,i] <- getParams(Ystar)
}
head(params)
hist(params[6,])
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i],
abline(v=0, col="red", lwd=2)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i])
abline(v=0, col="red", lwd=2)
}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
library(MASS)
# Read original dataset with minor changes
#X<-read.csv("Ray_et_all_2017.csv")
# Read revised dataset
X<-read.csv("projects.csv")
dimnames(X)[[2]]
pairs(X[,4:8], gap=0, pch='.')
# Create log-transformed data.
# Zero values in bcommits were replaced with 0.5 prior to the log transform.
# language_r is the same as language, but Scala is mentioned first (needed for NB)
Y <- data.frame(language=factor(X$language),
ldevs=log(X$devs),
lcommits=log(X$commits),
ltins=log(X$tins),
lmax_commit_age=log(X$max_commit_age),
lbcommits=log(X$bcommits + 0.5*(X$bcommits==0)),
bcommits=X$bcommits,
combined=factor(X$combined),
static=factor(X$static),
procedural=factor(X$procedural),
scripting=factor(X$scripting),
functional=factor(X$functional),
#                noconversion=factor(X$noconversion),
managed=factor(X$managed),
language_r = relevel(X$language, rev(levels(X$language))[1],),
commits = X$commits
)
pairs(Y[,2:6], gap=0, pch='.')
# Explore the relative frequencies of the languages
sort(table(Y$language))
# Explore the relationship between the languages, and other measurements
# (devs, tins, max_commit_age, commits, bcommits)
boxplot(split(Y$lbcommits, Y$language), las=2, main="Log(bugged commits, 0 replaced with 0.5)")
par(mfrow=c(1,2), oma=c(1,1,1,1), mar=c(5,1,2,1))
boxplot(split(Y$ldevs, Y$language), las=2, main="Log(devs)")
boxplot(split(Y$ltins, Y$language), las=2, main="Log(tins)")
boxplot(split(Y$lmax_commit_age, Y$language), las=2,
main="Log(max_commit_age)")
boxplot(split(Y$lcommits, Y$language), las=2, main="Log(commits)")
# Define the contrast as set up by the authors
contr.Weights <- function(fac)
{
fDist=summary(fac)
fSum=contr.sum(levels(fac))
fSum[nrow(fSum),] = -fDist[1:ncol(fSum)]/fDist[length(fDist)]
fSum
}
language_auth_contr <- contr.Weights(Y$language)
language_auth_contr
# Fit NB with the authors' contrast
nbfit_auth <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = contr.Weights(Y$language)), data=Y)
s_auth <- summary(nbfit_auth)$coefficients
s_auth
# Fit the releveled model with author's contrasts,
# to get the parameter for Scala
nbfit_auth_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = contr.Weights(Y$language_r)), data=Y)
s_auth_r <- summary(nbfit_auth_r)$coefficients
s_auth_r
# The significance level after adjustment for multiple testing
0.01/16
paramsNames <- c(dimnames(s)[[1]][1:5], names(summary(Y$language)))
cbind(paramsNames,
round(rbind(s_auth[,1:3], s_auth_r[6, 1:3]), digits=2),
c(s_auth[,4], s_auth_r[6,4]) < 0.01/16
)
contr.sum(16)
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Y)
s <- summary(nbfit)$coefficients
s
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Y)
s_r <- summary(nbfit_r)$coefficients
s_r
# The significance level after adjustment for multiple testing
0.01/16
cbind(paramsNames,
round(rbind(s[,1:3], s_r[6, 1:3]), digits=2),
c(s[,4], s_r[6,4]) < 0.01/16
)
nbfit_reduced <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits, data=Y)
summary(nbfit_reduced)
anova(nbfit_reduced, nbfit)
cat("AIC, full:", AIC(nbfit))
cat("AIC, reduced:", AIC(nbfit_reduced))
cat("BIC, full:", BIC(nbfit))
cat("BIC, reduced:", BIC(nbfit_reduced))
# Create a new data structure for prediction
newY <- NULL
for (i in 1:16) {
newY <- rbind(newY,
data.frame(language=rep(levels(Y$language)[i], 100),
ldevs=rep(median(Y$ldevs), 100),
lcommits=seq(from=min(Y$lcommits), to=max(Y$lcommits), length=100),
ltins=rep(median(Y$ltins), 100),
lmax_commit_age=rep(median(Y$lmax_commit_age), 100)))
}
newY$commits <- exp(newY$lcommits)
# Make predictions
pr_nbfit <- predict(nbfit, type="response", newdata=newY, se.fit=TRUE)
newY$pr_mean <- pr_nbfit$fit
newY$pr_se <- pr_nbfit$se.fit
par(mfrow=c(1,2))
# Log scale: confidence intervals for the top and bottom curves
# Empty plot
plot(log(pr_mean)~lcommits, main="log-CI for the mean\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlab="log(commits)", ylab="log(bugged commits)")
plotLines <- function(Ysub, col="black") {
lines(Ysub$lcommits, log(Ysub$pr_mean), lty=1, col=col)
lines(Ysub$lcommits, log(Ysub$pr_mean+qnorm(1-0.01/16)*Ysub$pr_se), lty=2, col=col)
lines(Ysub$lcommits, log(Ysub$pr_mean-qnorm(1-0.01/16)*Ysub$pr_se), lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
# Log scale: prediction intervals for the top and bottom curves
# Empty plot
plot(log(pr_mean)~lcommits, main="log-Prediction interval\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlab="log(commits)", ylab="log(bugged commits)")
plotLines <- function(Ysub, col="black") {
lines(Ysub$lcommits, log(Ysub$pr_mean), lty=1, col=col)
lines(Ysub$lcommits, log(qnbinom(1-0.01/16, mu=Ysub$pr_mean, size=nbfit$theta)),
lty=2, col=col)
lines(Ysub$lcommits, log(qnbinom(0.01/16, mu=Ysub$pr_mean, size=nbfit$theta)),
lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
par(mfrow=c(1,2))
# Original scale: confidence intervals for the top and bottom curves
# Empty plot
plot(pr_mean~commits, main="CI for the mean,\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlim=c(0, 800), ylim=c(0,400), xlab="commits", ylab="bugged commits")
plotLines <- function(Ysub, col="black") {
lines(Ysub$commits, Ysub$pr_mean, lty=1, col=col)
lines(Ysub$commits, Ysub$pr_mean+qnorm(1-0.01/16)*Ysub$pr_se, lty=2, col=col)
lines(Ysub$commits, Ysub$pr_mean-qnorm(1-0.01/16)*Ysub$pr_se, lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
# Original scale: prediction intervals for the top and bottom curves
# Empty plot
plot(pr_mean~commits, main="Prediction interval\nC++ (top), Clojure (bottom)",
data=newY[newY$language==levels(Y$language)[1],], type="n",
xlim=c(0, 800), ylim=c(0,400), xlab="commits", ylab="bugged commits")
plotLines <- function(Ysub, col="black") {
lines(Ysub$commits, Ysub$pr_mean, lty=1, col=col)
lines(Ysub$commits, qnbinom(1-0.01/16, mu=Ysub$pr_mean, size=nbfit$theta),
lty=2, col=col)
lines(Ysub$commits, qnbinom(0.01/16, mu=Ysub$pr_mean, size=nbfit$theta),
lty=2, col=col)
}
plotLines(newY[newY$language=="C++",], col="red")
plotLines(newY[newY$language=="Clojure",], col="blue")
# Plot predicted means for all the languages
par(mfrow=c(1,2))
# Log scale
plot(log(pr_mean)~lcommits, main="log(Exp. values), all languages",
data=newY[newY$language==levels(Y$language)[1],], type="l",
ylab="log(bugged commits)")
for (i in 2:16) {
lines(log(pr_mean)~lcommits,
data=newY[newY$language==levels(Y$language)[i],])
}
# Original scale
plot(pr_mean~commits, main="Exp. values, all languages",
data=newY[newY$language==levels(Y$language)[1],], type="l",
xlim=c(0, 800), ylim=c(0,400), ylab="bugged commits")
for (i in 2:16) {
lines(pr_mean~commits,
data=newY[newY$language==levels(Y$language)[i],])
}
# Set up probability of FP and FN
fp <- 0.3
fn <- 0.3
# Function to get parameter values
getParams <- function(Ystar) {
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Ystar)
s <- summary(nbfit)$coefficients
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Ystar)
s_r <- summary(nbfit_r)$coefficients
# Return params, incluing Scala
out <- c(s[,1], s_r[6, 1])
names(out) <- c(dimnames(s)[[1]][1:5], levels(Y$language))
out
}
# Perform sampling
set.seed(1)
params <- matrix(rep(NA,21*100), nrow=21)
for (i in 1:100) {
# Sample rows
Ystar <- Y[sample(1:nrow(Y), replace = T),]
# Adjust for tp and fp
Ystar$bcommits <- rbinom(n=nrow(Ystar), size=Ystar$bcommits, prob=1-fp) +
rbinom(n=nrow(Ystar), size=Ystar$commits, prob=fn)
# Get parameters
params[,i] <- getParams(Ystar)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i])
abline(v=0, col="red", lwd=2)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main="")
abline(v=0, col="red", lwd=2)
}
summary(params)
summary(as.vector(params))
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main="", xlim=c(-1.2, 1))
abline(v=0, col="red", lwd=2)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main="")
abline(v=0, col="red", lwd=2)
}
# Set up probability of FP and FN
fp <- 0.3
fn <- 0.3
# Function to get parameter values
getParams <- function(Ystar) {
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Ystar)
s <- summary(nbfit)$coefficients
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Ystar)
s_r <- summary(nbfit_r)$coefficients
# Return params, incluing Scala
out <- c(s[,1], s_r[6, 1])
names(out) <- c(dimnames(s)[[1]][1:5], levels(Y$language))
out
}
# Perform sampling
set.seed(1)
params <- matrix(rep(NA,21*100), nrow=21)
for (i in 1:100) {
# Sample rows
Ystar <- Y[sample(1:nrow(Y), replace = T),]
# Adjust for tp and fp:
# Reduce bcommits by prob 1-fp
# Increase non-bugged commits by prob fn
Ystar$bcommits <- rbinom(n=nrow(Ystar), size=Ystar$bcommits, prob=1-fp) +
rbinom(n=nrow(Ystar), size=(Ystar$commits-Ystar$bcommits), prob=fn)
# Get parameters
params[,i] <- getParams(Ystar)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main="")
abline(v=0, col="red", lwd=2)
}
s_r
s
# Set up probability of FP and FN
fp <- 0.3
fn <- 0.3
# Function to get parameter values
getParams <- function(Ystar) {
# Fit NB with standard contrasts
nbfit <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language,
contrasts = list(language = "contr.sum"), data=Ystar)
s <- summary(nbfit)$coefficients
# Fit the releveled model with standard contrasts,
# to get the parameter for Scala
nbfit_r <- glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r,
contrasts = list(language_r = "contr.sum"), data=Ystar)
s_r <- summary(nbfit_r)$coefficients
# Return params, incluing Scala
out <- c(s[,1], s_r[6, 1])
names(out) <- c(dimnames(s)[[1]][1:5], levels(Y$language))
out
}
# Perform sampling
set.seed(1)
params <- matrix(rep(NA,21*100), nrow=21)
for (i in 1:100) {
# Sample rows
Ystar <- Y[sample(1:nrow(Y), replace = T),]
# Adjust for tp and fp:
# Reduce bcommits by prob fp
# Increase non-bugged commits by prob fn
tmp <- rbinom(n=nrow(Ystar), size=Ystar$bcommits, prob=1-fp) +
rbinom(n=nrow(Ystar), size=(Ystar$commits-Ystar$bcommits), prob=fn)
Ystar$bcommits <- tmp
# Get parameters
params[,i] <- getParams(Ystar)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main="")
abline(v=0, col="red", lwd=2)
}
paramsNames
paramsNames[i]
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main=paste("mean =", round(mean(params[i,]), digits=2)),
abline(v=0, col="red", lwd=2)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i], main=paste("mean =", round(mean(params[i,]), digits=2))),
abline(v=0, col="red", lwd=2)
}
par(mfrow=c(2,4))
for ( i in 2:21)
{
hist(params[i,],
xlab=paramsNames[i],
main=paste("mean =", round(mean(params[i,]), digits=2))
)
abline(v=0, col="red", lwd=2)
}
xtable(c(1:10))
library(xtable)
xtable(c(1:10))
xtable(matrix(c(1:10), ncol=2))
dim(Y)
ls()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
library(MASS)
# Read original dataset with minor changes
#X<-read.csv("Ray_et_all_2017.csv")
# Read revised dataset
X<-read.csv("projects.csv")
dimnames(X)[[2]]
pairs(X[,4:8], gap=0, pch='.')
dim(X)
0.01/16
1-0.49
1-0.9
source('~/Documents/GitHub/DS5220/F18/build_site.R')
source('~/Documents/GitHub/DS5220/F18/build_site.R')
